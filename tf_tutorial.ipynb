{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to TensorFlow with Python\n",
    "\n",
    "TensorFlow:\n",
    "- Developed by Google Brain\n",
    "- Open Source\n",
    "- Data flow graphs\n",
    "- Mainly used for neural networks and deep learning\n",
    "- Can use the GPU to train much faster\n",
    "- Numerous APIs to make building neural networks and optimizers easy\n",
    "- deploy on CPUs or GPUs on desktops or servers\n",
    "\n",
    "![TF dataflow graph](images/tensors_flowing.gif)\n",
    "\n",
    "### Installing TensorFlow\n",
    "\n",
    "- `pip install tensorflow` for the CPU version\n",
    "\n",
    "\n",
    "- require GPU with CUDA support version 3.0 or higher\n",
    "- install CUDA\n",
    "- install CUDNN\n",
    "- `pip install tensorflow-gpu`\n",
    "\n",
    "\n",
    "- more information in the Confluence article and at [tensorflow.org](https://tensorflow.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(3.0)\n",
    "b = tf.constant(5.0)\n",
    "c = tf.multiply(a,b)\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TensorFlow also has Placeholders and Variables**\n",
    "- Placeholders are Tensors, which you can feed input to\n",
    "- Variables are tensors with weight, which can be changed during the sessions. Optimizers change the variables.\n",
    "\n",
    "**Loss functions and Optimizers:**\n",
    "- Loss functions measure errors between tensors\n",
    "- Optimizers, try to minimize the loss functions by updating all Variable tensors\n",
    "\n",
    "**Learning rate:**\n",
    "- parameter to give to the optimizer. Too high and you won't be able to get accurate results. Too low and and training will take way too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[])\n",
    "a = tf.Variable(2.0)\n",
    "y = tf.constant(6.0)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(\n",
    "            labels=y, \n",
    "            predictions=tf.multiply(a, x))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(train, feed_dict={x:2.00})\n",
    "sess.run(a, feed_dict={x:2.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "\n",
    "You can use the lowest level TF Core to create a Neural Network and this way you will have a lot of control on what's happening inside.\n",
    "\n",
    "However for most purposes you can use higher-level APIs such as.\n",
    "- `tf.layers` - For Dense, Convolutional and Pooling layers\n",
    "- `tf.losses` - For loss functions\n",
    "- `tf.train` - For Optimizers\n",
    "- `tf.estimator` - Makes running training and evaluation loops easier, and provides dataset management utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \n",
    "# https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_iris()\n",
    "features = data.data\n",
    "labels = data.target.reshape((-1, 1))\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "enc.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "                                features, \n",
    "                                enc.transform(labels) )\n",
    "\n",
    "x_size = train_x.shape[1]\n",
    "y_size = train_y.shape[1]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, x_size])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, y_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Network Model\n",
    "def hidden_layer(t_input, w_shape, activation=tf.nn.sigmoid):\n",
    "    biases = tf.Variable(tf.random_normal(w_shape))\n",
    "    weights = tf.Variable(tf.random_normal(w_shape))\n",
    "    return activation(tf.add(biases, tf.matmul(t_input, weights)))\n",
    "\n",
    "h_layer1 = hidden_layer(X, [x_size, 128])\n",
    "h_layer2 = hidden_layer(h_layer1, [128, 128])\n",
    "y_hat = hidden_layer(h_layer2, [128, y_size], tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_layer1 = tf.layers.dense(X, 128, activation=tf.nn.sigmoid)\n",
    "h_layer2 = tf.layers.dense(h_layer1, 128, activation=tf.nn.sigmoid)\n",
    "y_hat = tf.layers.dense(h_layer2, y_size, activation=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimization\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=Y, logits=y_hat))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.005).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "for epoch in range(300):\n",
    "    for i in range(train_x.shape[0]):\n",
    "        sess.run(train_step, feed_dict={X: train_x[i:i+1], Y: train_y[i: i+1]})                                                 \n",
    "        \n",
    "    if (epoch % 10 == 0):\n",
    "        correct_prediction = tf.equal(tf.argmax(y_hat, 1), tf.argmax(Y, 1))                                                      \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))                                                       \n",
    "        print(\"Epoch %d: Accuraccy = %f, Loss = %f\" % (                                                                          \n",
    "                          epoch,                                                                                                   \n",
    "                          sess.run(accuracy, feed_dict={X: test_x, Y: test_y}),                                                    \n",
    "                          sess.run(loss, feed_dict={X: train_x, Y: train_y})))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
